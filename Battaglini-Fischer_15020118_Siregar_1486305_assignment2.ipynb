{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Spatial Models - Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "from ndlib.utils import multi_runs\n",
    "\n",
    "import abc\n",
    "from bokeh.palettes import Category20_9 as cols\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import future.utils\n",
    "import six\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saved all of our plots for the second problem in a folder named 'assets' instead of using plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './'\n",
    "\n",
    "if not os.path.exists(os.path.join(filepath, 'assets')):\n",
    "    os.makedirs(os.path.join(filepath, 'assets'))\n",
    "    print(\"'assets' folder has been created in the specified filepath.\")\n",
    "else:\n",
    "    print(\"'assets' folder already exists in the specified filepath.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we override the DiffusionTrend function from Ndlib to customize the diffusion plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Giulio Rossetti\"\n",
    "__license__ = \"BSD-2-Clause\"\n",
    "__email__ = \"giulio.rossetti@gmail.com\"\n",
    "\n",
    "\n",
    "@six.add_metaclass(abc.ABCMeta)\n",
    "class DiffusionPlot(object):\n",
    "    def __init__(self, model, trends):\n",
    "        self.model = model\n",
    "        self.trends = trends\n",
    "        statuses = model.available_statuses\n",
    "        self.srev = {v: k for k, v in future.utils.iteritems(statuses)}\n",
    "        self.ylabel = \"\"\n",
    "        self.title = \"\"\n",
    "        self.nnodes = model.graph.number_of_nodes()\n",
    "        self.normalized = True\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def iteration_series(self, percentile):\n",
    "        \"\"\"\n",
    "        Prepare the data to be visualized\n",
    "\n",
    "        :param percentile: The percentile for the trend variance area\n",
    "        :return: a dictionary where iteration ids are keys and the associated values are the computed measures\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def plot(self, filename=None, percentile=90, statuses=None, descr=None):\n",
    "        \"\"\"\n",
    "        Generates the plot\n",
    "\n",
    "        :param filename: Output filename\n",
    "        :param percentile: The percentile for the trend variance area\n",
    "        :param statuses: List of statuses to plot. If not specified all statuses trends will be shown.\n",
    "        \"\"\"\n",
    "\n",
    "        pres = self.iteration_series(percentile)\n",
    "\n",
    "        plt.figure(figsize=(20, 15))\n",
    "\n",
    "        mx = 0\n",
    "        i = 0\n",
    "        for k, l in future.utils.iteritems(pres):\n",
    "\n",
    "            if statuses is not None and self.srev[k] not in statuses:\n",
    "                continue\n",
    "            mx = len(l[0])\n",
    "            if self.normalized:\n",
    "                plt.plot(\n",
    "                    range(0, mx),\n",
    "                    l[1] / self.nnodes,\n",
    "                    lw=2,\n",
    "                    label=self.srev[k],\n",
    "                    alpha=0.5,\n",
    "                )  # , color=cols[i])\n",
    "                plt.fill_between(\n",
    "                    range(0, mx), l[0] / self.nnodes, l[2] / self.nnodes, alpha=0.2\n",
    "                )\n",
    "                # ,color=cols[i])\n",
    "            else:\n",
    "                plt.plot(\n",
    "                    range(0, mx), l[1], lw=2, label=self.srev[k], alpha=0.5\n",
    "                )  # , color=cols[i])\n",
    "                plt.fill_between(range(0, mx), l[0], l[2], alpha=0.2)  # ,color=cols[i])\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        plt.grid(axis=\"y\")\n",
    "        plt.xlabel(\"Iterations\", fontsize=40)\n",
    "        plt.ylabel(self.ylabel, fontsize=40)\n",
    "        plt.tick_params(axis='both', which='major', labelsize=36)\n",
    "        plt.legend(loc=\"best\", fontsize=36)\n",
    "\n",
    "        if descr is not None:\n",
    "            plt.title(f\"fraction infected: {descr[0]}, beta: {descr[1]}, gamma: {descr[2]}\", fontsize=38) \n",
    "        plt.xlim((0, mx))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if filename is not None:\n",
    "            plt.savefig(filename)\n",
    "            plt.clf()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "class DiffusionTrend(DiffusionPlot):\n",
    "    def __init__(self, model, trends):\n",
    "        \"\"\"\n",
    "        :param model: The model object\n",
    "        :param trends: The computed simulation trends\n",
    "        \"\"\"\n",
    "        super(self.__class__, self).__init__(model, trends)\n",
    "        self.ylabel = \"#Nodes\"\n",
    "        self.title = \"Diffusion Trend\"\n",
    "\n",
    "    def iteration_series(self, percentile):\n",
    "\n",
    "        series = {k: [] for k in self.srev.keys()}\n",
    "\n",
    "        presences = {k: [] for k in self.srev.keys()}\n",
    "        for t in self.trends:\n",
    "\n",
    "            for st in t:\n",
    "                for k in t[st][\"node_count\"]:\n",
    "                    presences[k].append(np.array(t[st][\"node_count\"][k]))\n",
    "\n",
    "        for st in presences:\n",
    "            tp = np.percentile(np.array(presences[st]), percentile, axis=0)\n",
    "            bp = np.percentile(np.array(presences[st]), 100 - percentile, axis=0)\n",
    "            av = np.average(np.array(presences[st]), axis=0)\n",
    "            series[st] = (tp, av, bp)\n",
    "\n",
    "        return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to implement SIR disease spread on the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, num_of_nodes):\n",
    "        self.num_of_nodes = num_of_nodes\n",
    "\n",
    "    def barabasi_albert(self, num_of_edges):\n",
    "        return nx.barabasi_albert_graph(self.num_of_nodes, num_of_edges)\n",
    "\n",
    "    def watts_strogatz(self, k_nearest_neighbors, rewiring_probability):\n",
    "        return nx.watts_strogatz_graph(self.num_of_nodes, k_nearest_neighbors, rewiring_probability)\n",
    "\n",
    "    def erdos_renyi(self, edge_creation_probability):\n",
    "        return nx.erdos_renyi_graph(self.num_of_nodes, edge_creation_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_config(beta, gamma, fraction_infected):\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "    config.add_model_parameter(\"fraction_infected\", fraction_infected)\n",
    "    return config\n",
    "\n",
    "def run_simulation(beta, gamma, fraction_infected, graph, network_abbrv):        \n",
    "    config = set_config(beta, gamma, fraction_infected)\n",
    "    sir_model = ep.SIRModel(graph)\n",
    "    sir_model.set_initial_status(config)\n",
    "    trends = multi_runs(sir_model, execution_number=10, iteration_number=100, infection_sets=None, nprocesses=4)\n",
    "    viz = DiffusionTrend(sir_model, trends)\n",
    "    viz.plot(filename=f\"./assets/{network_abbrv}_trend_beta{beta}_gamma{gamma}_infected{fraction_infected}.png\", descr=[fraction_infected, beta, gamma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run multiple simulations across different network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set network model params\n",
    "N = 1000\n",
    "graph = Graph(num_of_nodes=N)\n",
    "ba_graph = graph.barabasi_albert(num_of_edges=5)\n",
    "ws_graph = graph.watts_strogatz(k_nearest_neighbors=6, rewiring_probability=0.1)\n",
    "er_graph = graph.erdos_renyi(edge_creation_probability=0.1)\n",
    "\n",
    "# Set disease params\n",
    "infection_rate = 0.3\n",
    "recovery_rate = 0.1\n",
    "fraction = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_simulation(infection_rate, recovery_rate, fraction, ba_graph, 'BA')\n",
    "run_simulation(infection_rate, recovery_rate, fraction, ws_graph, 'WS')\n",
    "run_simulation(infection_rate, recovery_rate, fraction, er_graph, 'ER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to see how varying the number of nodes affect the average shortest path length across network types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_shortest_path_length(N):\n",
    "    graph = Graph(num_of_nodes=N)\n",
    "    \n",
    "    ba_graph = graph.barabasi_albert(num_of_edges=5)\n",
    "    ws_graph = graph.watts_strogatz(k_nearest_neighbors=6, rewiring_probability=0.1)\n",
    "    er_graph = graph.erdos_renyi(edge_creation_probability=0.1)\n",
    "    \n",
    "    ba_avg_len = nx.average_shortest_path_length(ba_graph)\n",
    "    ws_avg_len = nx.average_shortest_path_length(ws_graph)\n",
    "    er_avg_len = nx.average_shortest_path_length(er_graph)\n",
    "    \n",
    "    return ba_avg_len, ws_avg_len, er_avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_values = [100, 1000, 10000]\n",
    "\n",
    "ba_results = []\n",
    "ws_results = []\n",
    "er_results = []\n",
    "\n",
    "for N in N_values:\n",
    "    ba_len, ws_len, er_len = compute_average_shortest_path_length(N)\n",
    "    ba_results.append(ba_len)\n",
    "    ws_results.append(ws_len)\n",
    "    er_results.append(er_len)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.loglog(N_values, ba_results, 'o-', label='Barabási-Albert')\n",
    "plt.loglog(N_values, ws_results, 'o-', label='Watts-Strogatz')\n",
    "plt.loglog(N_values, er_results, 'o-', label='Erdős–Rényi')\n",
    "\n",
    "bar_width = 0.25\n",
    "r1 = np.arange(len(N_values))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "r3 = [x + bar_width for x in r2]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.bar(r1, ba_results, color='#122640', width=bar_width, edgecolor='grey', label='Barabasi-Albert', log=True)\n",
    "plt.bar(r2, ws_results, color='#558F8B', width=bar_width, edgecolor='grey', label='Watts-Strogatz', log=True)\n",
    "plt.bar(r3, er_results, color='#B8D5B2', width=bar_width, edgecolor='grey', label='Erdos-Renyi', log=True)\n",
    "\n",
    "plt.xlabel('Number of nodes', fontweight='bold', fontsize=15)\n",
    "plt.xticks([r + bar_width for r in range(len(ba_results))], ['100', '1000', '10000'])\n",
    "plt.ylabel('Average shortest path length', fontweight='bold', fontsize=15)\n",
    "plt.yticks([2, 3, 4, 5, 6, 7, 8, 9], ['2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.title('Average shortest path length vs. Number of nodes', fontsize=20)\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\", c='0.65')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./assets/stats_avg_shortest_path_length.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see network statistics, we will vary the parameter setting for each network model while keeping the number of nodes constant to 1000. To do this, we need to create the instances of Graph class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "graph = Graph(num_of_nodes=N)\n",
    "ba_num_of_edges = range(2, 11) \n",
    "ws_k_nearest_neighbors = range(4, 10)\n",
    "ws_rewiring_probabilities = [0.01, 0.1, 0.5, 1.0] \n",
    "er_creation_probabilities = [0.05, 0.1, 0.5, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_degrees = []\n",
    "ws_degrees = []\n",
    "er_degrees = []\n",
    "\n",
    "for edge in ba_num_of_edges:\n",
    "    ba_graph = graph.barabasi_albert(num_of_edges=edge)\n",
    "    ba_degrees.extend(list(nx.degree_centrality(ba_graph).values()))\n",
    "\n",
    "for k in ws_k_nearest_neighbors:\n",
    "    for p in ws_rewiring_probabilities :\n",
    "        ws_graph = graph.watts_strogatz(k_nearest_neighbors=k, rewiring_probability=p)\n",
    "        ws_degrees.extend(list(nx.degree_centrality(ws_graph).values()))\n",
    "\n",
    "for p in er_creation_probabilities:\n",
    "    er_graph = graph.erdos_renyi(edge_creation_probability=p)\n",
    "    er_degrees.extend(list(nx.degree_centrality(er_graph).values()))\n",
    "\n",
    "def plot_degree_distribution(network_abbrv):\n",
    "    if network_abbrv == 'ba':\n",
    "        title = 'Barabási-Albert Degree Distributions'\n",
    "        degrees = ba_degrees\n",
    "    elif network_abbrv == 'er':\n",
    "        title = 'Erdős–Rényi Degree Distributions'\n",
    "        degrees = er_degrees\n",
    "    elif network_abbrv == 'ws':\n",
    "        title = 'Watts-Strogatz Degree Distributions'\n",
    "        degrees = ws_degrees\n",
    "\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    plt.hist(degrees, bins=30, color='skyblue', edgecolor='black')\n",
    "    plt.xlabel('Degree Centrality', fontsize=32)\n",
    "    plt.xticks(fontsize=24) \n",
    "    plt.ylabel('Frequency', fontsize=32)\n",
    "    plt.yticks(fontsize=24) \n",
    "    plt.savefig(f'./assets/{network_abbrv}_degree_centrality_distribution.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_distribution('ba')\n",
    "plot_degree_distribution('ws')\n",
    "plot_degree_distribution('er')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_avg_degree_centralities = []\n",
    "ws_avg_degree_centralities = []\n",
    "er_avg_degree_centralities = []\n",
    "\n",
    "for edge in ba_num_of_edges:\n",
    "    ba_graph = graph.barabasi_albert(num_of_edges=edge)\n",
    "    avg_degree_centrality = sum(nx.degree_centrality(ba_graph).values()) / N\n",
    "    ba_avg_degree_centralities.append(avg_degree_centrality)\n",
    "\n",
    "# Visualization for Barabási-Albert Average Degree Centrality\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.bar(range(len(ba_avg_degree_centralities)), ba_avg_degree_centralities, color='skyblue')\n",
    "plt.xlabel('Edges', fontsize=32)\n",
    "plt.xticks(fontsize=24) \n",
    "plt.ylabel('Average Centrality Measures', fontsize=32)\n",
    "plt.yticks(fontsize=24) \n",
    "plt.savefig('./assets/ba_centrality.png')\n",
    "plt.close()\n",
    "\n",
    "for k in ws_k_nearest_neighbors:\n",
    "    for p in ws_rewiring_probabilities:\n",
    "        ws_graph = graph.watts_strogatz(k_nearest_neighbors=k, rewiring_probability=p)\n",
    "        avg_degree_centrality = sum(nx.degree_centrality(ws_graph).values()) / N\n",
    "        ws_avg_degree_centralities.append(avg_degree_centrality)\n",
    "\n",
    "# Visualization for Watts-Strogatz Average Degree Centrality\n",
    "plt.figure(figsize=(15, 12))\n",
    "bars = plt.bar(range(len(ws_avg_degree_centralities)), ws_avg_degree_centralities, color='salmon')\n",
    "plt.xlabel('K Nearest Neighbors', fontsize=32)\n",
    "plt.xticks(fontsize=24) \n",
    "plt.ylabel('Average Centrality Measures', fontsize=32)\n",
    "plt.yticks(fontsize=24) \n",
    "for idx, bar in enumerate(bars):\n",
    "    rewiring_prob = ws_rewiring_probabilities[idx % len(ws_rewiring_probabilities)]\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2 - 0.15, \n",
    "             bar.get_height() - 0.0005, \n",
    "             f'p = {rewiring_prob}', \n",
    "             ha='center', \n",
    "             color='black',\n",
    "             rotation=45,\n",
    "             fontsize=6)\n",
    "plt.savefig('./assets/ws_centrality.png')\n",
    "plt.close()\n",
    "\n",
    "for p in er_creation_probabilities:\n",
    "    er_graph = graph.erdos_renyi(edge_creation_probability=p)\n",
    "    avg_degree_centrality = sum(nx.degree_centrality(er_graph).values()) / N\n",
    "    er_avg_degree_centralities.append(avg_degree_centrality)\n",
    "\n",
    "# Visualization for Erdős–Rényi Average Degree Centrality\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.bar(range(len(er_avg_degree_centralities)), er_avg_degree_centralities, color='lightgreen')\n",
    "plt.xlabel('Edge Creation Probability', fontsize=32)\n",
    "plt.xticks(fontsize=24) \n",
    "plt.ylabel('Average Centrality Measures', fontsize=32)\n",
    "plt.yticks(fontsize=24) \n",
    "plt.savefig('./assets/er_centrality.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network topology\n",
    "N = 1000\n",
    "graph = Graph(num_of_nodes=N)\n",
    "ba_graph = graph.barabasi_albert(num_of_edges=10)\n",
    "ws_graph = graph.watts_strogatz(k_nearest_neighbors=6, rewiring_probability=0.5)\n",
    "er_graph = graph.erdos_renyi(edge_creation_probability=0.5)\n",
    "\n",
    "# Disease parameters\n",
    "beta = 0.3\n",
    "gamma = 0.1\n",
    "fraction_infected = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_spread(graph_type, network_abbrv):\n",
    "    node_degrees = nx.degree_centrality(graph_type)\n",
    "    top_3_highest = sorted(node_degrees.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "    top_4_lowest = sorted(node_degrees.items(), key=lambda x: x[1])[:4]\n",
    "\n",
    "    # Remove selected nodes and pick random 3 nodes\n",
    "    selected_nodes = [node[0] for node in top_3_highest + top_4_lowest]\n",
    "    remaining_nodes = [k for k, v in node_degrees.items() if k not in selected_nodes]\n",
    "    random_3_keys = random.sample(remaining_nodes, 3)\n",
    "    random_3 = [(key, node_degrees[key]) for key in random_3_keys]\n",
    "\n",
    "    top_3_highest_degree_nodes = [node[0] for node in top_3_highest]\n",
    "    top_4_lowest_degree_nodes = [node[0] for node in top_4_lowest]\n",
    "    random_nodes = [node[0] for node in random_3]\n",
    "\n",
    "    # Model selection\n",
    "    model = ep.SIRModel(graph_type)\n",
    "\n",
    "    # Model Configuration\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', beta)\n",
    "    config.add_model_parameter('gamma', gamma)\n",
    "    config.add_model_parameter(\"fraction_infected\", fraction_infected)\n",
    "    model.set_initial_status(config)\n",
    "\n",
    "    # Simulation multiple execution\n",
    "    infection_sets = [tuple(top_3_highest_degree_nodes), tuple(top_4_lowest_degree_nodes), tuple(random_nodes)]\n",
    "    trends = multi_runs(model, execution_number=3, iteration_number=100, infection_sets=infection_sets, nprocesses=4)\n",
    "    viz = DiffusionTrend(model, trends)\n",
    "    viz.plot(f\"./assets/{network_abbrv}_simulation_spread.png\", percentile=90, descr=[fraction_infected, beta, gamma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_spread(ba_graph, 'BA')\n",
    "simulate_spread(ws_graph, 'WS')\n",
    "simulate_spread(er_graph, 'ER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For vaccination strategy, first we import the csv file and ensure we have the correct number of nodes and edges. You need to have this csv file in the specified filepath, otherwise the code wont work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('transmission_network.csv', delimiter=';', index_col=0) \n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(data.index.tolist())\n",
    "G.add_nodes_from(data.columns.astype(int).tolist())\n",
    "\n",
    "rows = data.index.tolist()\n",
    "columns = data.columns.astype(int).tolist()\n",
    "\n",
    "if G.number_of_nodes() != 374:\n",
    "    raise ValueError(\"The number of nodes is not 364.\")\n",
    "\n",
    "for i, row in enumerate(rows):\n",
    "    for j, col in enumerate(columns):\n",
    "        value = data.iloc[i, j]\n",
    "        if value > 0:\n",
    "            G.add_edge(row, col, weight=value)\n",
    "            \n",
    "if  G.number_of_edges() != 1265:\n",
    "    raise ValueError(\"The number of edges is not 1265.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a dynamic vaccination strategy and compare it with a null strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_vaccination_strategy(graph, model, budget, vaccination_budget, test_accuracy):\n",
    "    node_degrees = dict(graph.degree())\n",
    "    sorted_nodes_by_high_degree = sorted(node_degrees, key=node_degrees.get, reverse=True)\n",
    "\n",
    "    tests_run = 0\n",
    "\n",
    "    while tests_run < budget:\n",
    "        for node in sorted_nodes_by_high_degree:\n",
    "            if tests_run < budget:\n",
    "                if random.random() < test_accuracy:\n",
    "                    node_status = model.status[node]\n",
    "                    # If the node is susceptible, vaccinate\n",
    "                    if node_status == 0:\n",
    "                        model.status[node] = 2  # Move to removed state\n",
    "                        tests_run += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "def run_simulation(graph, total_tests, vaccination_budget, test_accuracy, strategy=\"dynamic\"):\n",
    "    model = ep.SIRModel(graph)\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('beta', 0.3)\n",
    "    config.add_model_parameter('gamma', 0.1)\n",
    "    config.add_model_initial_configuration(\"Infected\", random.sample(list(graph.nodes()), 5))\n",
    "    model.set_initial_status(config)\n",
    "    \n",
    "    if strategy == \"dynamic\":\n",
    "        dynamic_vaccination_strategy(graph, model, total_tests, vaccination_budget, test_accuracy)\n",
    "    elif strategy == \"null\":\n",
    "        for _ in range(vaccination_budget):\n",
    "            null_node = random.choice(list(graph.nodes()))\n",
    "            model.status[null_node] = 2\n",
    "    else:\n",
    "        raise ValueError(\"Invalid strategy\")\n",
    "\n",
    "    iterations = model.iteration_bunch(200)\n",
    "    \n",
    "    return model, iterations\n",
    "\n",
    "def run_all_strategies(graph, total_tests, vaccination_budget, test_accuracy):\n",
    "    model_dynamic, iterations_dynamic = run_simulation(graph, total_tests, vaccination_budget, test_accuracy, strategy=\"dynamic\")\n",
    "    model_null, iterations_null = run_simulation(graph, total_tests, vaccination_budget, test_accuracy, strategy=\"null\")\n",
    "\n",
    "    return {\n",
    "        'model_dynamic': model_dynamic,\n",
    "        'iterations_dynamic': iterations_dynamic,\n",
    "        'model_null': model_null,\n",
    "        'iterations_null': iterations_null\n",
    "    }\n",
    "\n",
    "results = []\n",
    "budgets = [1, 3, 5, 10]\n",
    "accuracies = [0.5, 0.75, 1.0]\n",
    "\n",
    "for budget in budgets:\n",
    "    for accuracy in accuracies:\n",
    "        result = run_all_strategies(G, 200, budget, accuracy)\n",
    "        results.append({\n",
    "            'budget': budget,\n",
    "            'accuracy': accuracy,\n",
    "            'model_dynamic': result['model_dynamic'],\n",
    "            'iterations_dynamic': result['iterations_dynamic'],\n",
    "            'model_null': result['model_null'],\n",
    "            'iterations_null': result['iterations_null']\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the vaccination strategies with different vaccination budgets per time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    infected_dynamic = [it['node_count'][1] for it in result['iterations_dynamic']]\n",
    "    infected_null = [it['node_count'][1] for it in result['iterations_null']]\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.plot(infected_null, label=\"Infected, null strategy\")\n",
    "    plt.plot(infected_dynamic, label=\"Infected, dynamic strategy\", color=\"orange\")\n",
    "    \n",
    "    plt.xlabel(\"Time\", fontsize=26)\n",
    "    plt.xticks(fontsize=24)\n",
    "    plt.ylabel(\"Number of individuals\", fontsize=26)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.title(f\"beta = 0.3, gamma = 0.1, accuracy = {result['accuracy']}, vaccination budget = {result['budget']}\", fontsize=24)\n",
    "    \n",
    "    plt.legend(fontsize=24)\n",
    "    plt.savefig(f\"./assets/accuracy_{result['accuracy']}_vaccination_budget_{result['budget']}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the SIR spread when vaccination budget is 5 with accuracy of 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_example = 5\n",
    "accuracy_example = 0.75\n",
    "\n",
    "for result in results:\n",
    "    if result['budget'] == budget_example and result['accuracy'] == accuracy_example:\n",
    "        viz_dynamic = DiffusionTrend(result['model_dynamic'], result['model_dynamic'].build_trends(result['iterations_dynamic']))\n",
    "        viz_dynamic.plot(\"./assets/DynamicStrategy.png\")\n",
    "\n",
    "        viz_random = DiffusionTrend(result['model_null'], result['model_null'].build_trends(result['iterations_null']))\n",
    "        viz_random.plot(\"./assets/NullStrategy.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Gillespie’s Direct Algorithm and Stochastic Hallmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from ipywidgets import interact, FloatSlider\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing SIR_model and Gillespie's Algorithm functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIR_model(y, t, beta, gamma):\n",
    "    S, I, R = y\n",
    "    dS_dt = -beta * S * I / (S + I + R)\n",
    "    dI_dt = beta * S * I / (S + I + R) - gamma * I\n",
    "    dR_dt = gamma * I\n",
    "    return [dS_dt, dI_dt, dR_dt]\n",
    "\n",
    "def SIR_demography(y, t, beta, gamma, Lambda, mu):\n",
    "    S, I, R = y\n",
    "    dS_dt = Lambda - beta * S * I / (S + I + R) - mu * S\n",
    "    dI_dt = beta * S * I / (S + I + R) - gamma * I - mu * I\n",
    "    dR_dt = gamma * I - mu * R\n",
    "    return [dS_dt, dI_dt, dR_dt]\n",
    "\n",
    "def gillespie_algorithm(S0, I0, R0, beta, gamma, max_time):\n",
    "    S, I, R = S0, I0, R0\n",
    "    t = 0\n",
    "    times = [t]\n",
    "    S_values = [S]\n",
    "    I_values = [I]\n",
    "    R_values = [R]\n",
    "\n",
    "    while t < max_time and I > 0:\n",
    "        N = S + I + R\n",
    "\n",
    "        # Calculate propensities\n",
    "        a1 = beta * S * I / N\n",
    "        a2 = gamma * I\n",
    "        a0 = a1 + a2\n",
    "\n",
    "        # Time until next event\n",
    "        dt = -np.log(np.random.random()) / a0\n",
    "        t += dt\n",
    "\n",
    "        # Determine which event occurs\n",
    "        r = np.random.random()\n",
    "        if r < a1 / a0:\n",
    "            # Transmission event\n",
    "            S -= 1\n",
    "            I += 1\n",
    "        else:\n",
    "            # Recovery event\n",
    "            I -= 1\n",
    "            R += 1\n",
    "\n",
    "        # Store results\n",
    "        times.append(t)\n",
    "        S_values.append(S)\n",
    "        I_values.append(I)\n",
    "        R_values.append(R)\n",
    "\n",
    "    return times, S_values, I_values, R_values\n",
    "\n",
    "def GA_with_demography(S0, I0, R0, beta, gamma, Lambda, mu, max_time):\n",
    "    S, I, R = S0, I0, R0\n",
    "    t = 0\n",
    "    times = [t]\n",
    "    S_values = [S]\n",
    "    I_values = [I]\n",
    "    R_values = [R]\n",
    "\n",
    "    while t < max_time and I > 0:\n",
    "        N = S + I + R\n",
    "\n",
    "        # Calculate propensities\n",
    "        a1 = beta * S * I / N        # Transmission\n",
    "        a2 = gamma * I               # Recovery\n",
    "        a3 = Lambda                  # Birth\n",
    "        a4 = mu * S                  # Death of a susceptible\n",
    "        a5 = mu * I                  # Death of an infected\n",
    "        a6 = mu * R                  # Death of a recovered\n",
    "        \n",
    "        a0 = a1 + a2 + a3 + a4 + a5 + a6\n",
    "\n",
    "        # Time until next event\n",
    "        dt = -np.log(np.random.random()) / a0\n",
    "        t += dt\n",
    "\n",
    "        # Determine which event occurs\n",
    "        r = np.random.random() * a0\n",
    "        if r < a1:\n",
    "            # Transmission event\n",
    "            S -= 1\n",
    "            I += 1\n",
    "        elif r < a1 + a2:\n",
    "            # Recovery event\n",
    "            I -= 1\n",
    "            R += 1\n",
    "        elif r < a1 + a2 + a3:\n",
    "            # Birth event\n",
    "            S += 1\n",
    "        elif r < a1 + a2 + a3 + a4:\n",
    "            # Death of a susceptible\n",
    "            S -= 1\n",
    "        elif r < a1 + a2 + a3 + a4 + a5:\n",
    "            # Death of an infected\n",
    "            I -= 1\n",
    "        else:\n",
    "            # Death of a recovered\n",
    "            R -= 1\n",
    "\n",
    "        # Store results\n",
    "        times.append(t)\n",
    "        S_values.append(S)\n",
    "        I_values.append(I)\n",
    "        R_values.append(R)\n",
    "\n",
    "    return times, S_values, I_values, R_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the transmission rate to 0.3, recovery rate to 0.1. The initial number of susceptible and infected individuals can vary, the initial number of recovered individual is always 0. We can also set how many times we want to run the Gillespie's Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIR model without demography\n",
    "beta = 0.3\n",
    "gamma = 0.1\n",
    "max_time = 200\n",
    "t = np.linspace(0, max_time, 1000)\n",
    "output = widgets.Output()\n",
    "\n",
    "def update_plot(S0, I0, num_runs):\n",
    "    R0 = 0\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Solve ODE for deterministic SIR\n",
    "    solution = odeint(SIR_model, [S0, I0, R0], t, args=(beta, gamma))\n",
    "    S_det, I_det, R_det = solution.T\n",
    "\n",
    "    # Run Gillespie algorithm multiple times\n",
    "    all_S = []\n",
    "    all_I = []\n",
    "    all_R = []\n",
    "\n",
    "    for _ in range(num_runs):\n",
    "        times, S_values, I_values, R_values = gillespie_algorithm(S0, I0, R0, beta, gamma, max_time)\n",
    "        all_S.append(np.interp(t, times, S_values))\n",
    "        all_I.append(np.interp(t, times, I_values))\n",
    "        all_R.append(np.interp(t, times, R_values))\n",
    "\n",
    "    # Compute average and standard deviation\n",
    "    avg_S = np.mean(all_S, axis=0)\n",
    "    std_S = np.std(all_S, axis=0)\n",
    "    avg_I = np.mean(all_I, axis=0)\n",
    "    std_I = np.std(all_I, axis=0)\n",
    "\n",
    "    # Deterministic SIR\n",
    "    ax.plot(t, S_det, label=\"Susceptible (Deterministic)\", linestyle=\"--\")\n",
    "    ax.plot(t, I_det, label=\"Infectious (Deterministic)\", linestyle=\"--\")\n",
    "\n",
    "    # Average Stochastic SIR\n",
    "    ax.plot(t, avg_S, label=\"Avg Susceptible (Stochastic)\")\n",
    "    ax.fill_between(t, avg_S - std_S, avg_S + std_S, alpha=0.2)\n",
    "    ax.plot(t, avg_I, label=\"Avg Infectious (Stochastic)\")\n",
    "    ax.fill_between(t, avg_I - std_I, avg_I + std_I, alpha=0.2)\n",
    "\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Population\")\n",
    "    ax.set_title(f\"Comparison of Deterministic and Stochastic SIR Models ({num_runs} runs)\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "S0_slider = widgets.IntSlider(value=990, min=0, max=1000, step=10, description='S0:')\n",
    "I0_slider = widgets.IntSlider(value=10, min=0, max=100, step=10, description='I0:')\n",
    "num_runs_slider = widgets.IntSlider(value=1000, min=1, max=1000, description='GA Run:')\n",
    "\n",
    "\n",
    "widgets.interactive(update_plot, S0=S0_slider, I0=I0_slider, num_runs=num_runs_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIR model with demography\n",
    "beta = 0.3\n",
    "gamma = 0.1\n",
    "Lambda = 5  # birth rate\n",
    "mu = 0.01  # death rate\n",
    "max_time = 200\n",
    "t = np.linspace(0, max_time, 1000)\n",
    "output = widgets.Output()\n",
    "\n",
    "def update_plot(S0, I0, num_runs):\n",
    "    R0 = 0\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "        # Solve ODE for deterministic SIR\n",
    "        solution = odeint(SIR_demography, [S0, I0, R0], t, args=(beta, gamma, Lambda, mu))\n",
    "        S_det, I_det, R_det = solution.T\n",
    "\n",
    "        # Run Gillespie algorithm multiple times\n",
    "        all_S = []\n",
    "        all_I = []\n",
    "        all_R = []\n",
    "\n",
    "        for _ in range(num_runs):\n",
    "            times, S_values, I_values, R_values = GA_with_demography(S0, I0, R0, beta, gamma, Lambda, mu, max_time)\n",
    "            all_S.append(np.interp(t, times, S_values))\n",
    "            all_I.append(np.interp(t, times, I_values))\n",
    "            all_R.append(np.interp(t, times, R_values))\n",
    "\n",
    "        # Compute average and standard deviation\n",
    "        avg_S = np.mean(all_S, axis=0)\n",
    "        std_S = np.std(all_S, axis=0)\n",
    "        avg_I = np.mean(all_I, axis=0)\n",
    "        std_I = np.std(all_I, axis=0)\n",
    "\n",
    "        # Deterministic SIR\n",
    "        ax.plot(t, S_det, color='cornflowerblue', label=\"Susceptible (Deterministic)\", linestyle=\"--\")\n",
    "        ax.plot(t, I_det, color='purple', label=\"Infectious (Deterministic)\", linestyle=\"--\")\n",
    "\n",
    "        # Average Stochastic SIR\n",
    "        ax.plot(t, avg_S, color='green', label=\"Avg Susceptible (Stochastic)\")\n",
    "        ax.fill_between(t, avg_S - std_S, avg_S + std_S, color='green', alpha=0.2)\n",
    "        ax.plot(t, avg_I, color='red', label=\"Avg Infectious (Stochastic)\")\n",
    "        ax.fill_between(t, avg_I - std_I, avg_I + std_I, color='red', alpha=0.2)\n",
    "\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.set_ylabel(\"Population\")\n",
    "        ax.set_title(f\"Comparison of Deterministic and Stochastic SIR Models with Demography ({num_runs} runs)\")\n",
    "        ax.legend(loc=\"upper right\")\n",
    "        ax.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "S0_slider = widgets.IntSlider(value=90, min=0, max=1000, step=10, description='S0:')\n",
    "I0_slider = widgets.IntSlider(value=10, min=0, max=100, step=10, description='I0:')\n",
    "num_runs_slider = widgets.IntSlider(value=1, min=1, max=1000, description='GA Run:')\n",
    "\n",
    "\n",
    "interactive_plot = widgets.interactive(update_plot, S0=S0_slider, I0=I0_slider, num_runs=num_runs_slider)\n",
    "display(interactive_plot, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tau-leaping for noise control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_with_tau_leaping(S0, I0, R0, beta, gamma, Lambda, mu, max_time, tau):\n",
    "    S, I, R = S0, I0, R0\n",
    "    t = 0\n",
    "    times = [t]\n",
    "    S_values = [S]\n",
    "    I_values = [I]\n",
    "    R_values = [R]\n",
    "\n",
    "    while t < max_time and I > 0:\n",
    "        N = S + I + R\n",
    "\n",
    "        # Calculate propensities\n",
    "        a1 = beta * S * I / N\n",
    "        a2 = gamma * I\n",
    "        a3 = Lambda\n",
    "        a4 = mu * S\n",
    "        a5 = mu * I\n",
    "        a6 = mu * R\n",
    "        \n",
    "        # Estimate number of reactions in the time interval tau\n",
    "        num_a1 = np.random.poisson(a1 * tau)\n",
    "        num_a2 = np.random.poisson(a2 * tau)\n",
    "        num_a3 = np.random.poisson(a3 * tau)\n",
    "        num_a4 = np.random.poisson(a4 * tau)\n",
    "        num_a5 = np.random.poisson(a5 * tau)\n",
    "        num_a6 = np.random.poisson(a6 * tau)\n",
    "\n",
    "        # Update states based on estimated number of reactions\n",
    "        S += num_a3 - num_a1 - num_a4\n",
    "        I += num_a1 - num_a2 - num_a5\n",
    "        R += num_a2 - num_a6\n",
    "\n",
    "        t += tau\n",
    "\n",
    "        # Store results\n",
    "        times.append(t)\n",
    "        S_values.append(S)\n",
    "        I_values.append(I)\n",
    "        R_values.append(R)\n",
    "\n",
    "    return times, S_values, I_values, R_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIR model with demography\n",
    "beta = 0.3\n",
    "gamma = 0.1\n",
    "Lambda = 5 \n",
    "mu = 0.01 \n",
    "max_time = 200\n",
    "t = np.linspace(0, max_time, 1000)\n",
    "output = widgets.Output()\n",
    "\n",
    "def SIR_demography(Y, t, beta, gamma, Lambda, mu):\n",
    "    S, I, R = Y\n",
    "\n",
    "    N = S + I + R\n",
    "    dS = Lambda - beta * S * I / N - mu * S\n",
    "    dI = beta * S * I / N - gamma * I - mu * I\n",
    "    dR = gamma * I - mu * R\n",
    "\n",
    "    return [dS, dI, dR]\n",
    "\n",
    "def update_plot(S0, I0, tau, num_runs):\n",
    "    R0 = 0\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "        solution = odeint(SIR_demography, [S0, I0, R0], t, args=(beta, gamma, Lambda, mu))\n",
    "        S_det, I_det, R_det = solution.T\n",
    "\n",
    "        all_S_GA = []\n",
    "        all_I_GA = []\n",
    "        all_S_tau = []\n",
    "        all_I_tau = []\n",
    "\n",
    "        for _ in range(num_runs):\n",
    "            times_GA, S_values_GA, I_values_GA, R_values_GA = GA_with_demography(S0, I0, R0, beta, gamma, Lambda, mu, max_time)\n",
    "            times_tau, S_values_tau, I_values_tau, R_values_tau = GA_with_tau_leaping(S0, I0, R0, beta, gamma, Lambda, mu, max_time, tau=0.2)\n",
    "\n",
    "            all_S_GA.append(np.interp(t, times_GA, S_values_GA))\n",
    "            all_I_GA.append(np.interp(t, times_GA, I_values_GA))\n",
    "            all_S_tau.append(np.interp(t, times_tau, S_values_tau))\n",
    "            all_I_tau.append(np.interp(t, times_tau, I_values_tau))\n",
    "\n",
    "        # Compute averages and standard deviations for both algorithms\n",
    "        avg_S_GA = np.mean(all_S_GA, axis=0)\n",
    "        std_S_GA = np.std(all_S_GA, axis=0)\n",
    "        avg_I_GA = np.mean(all_I_GA, axis=0)\n",
    "        std_I_GA = np.std(all_I_GA, axis=0)\n",
    "        avg_S_tau = np.mean(all_S_tau, axis=0)\n",
    "        std_S_tau = np.std(all_S_tau, axis=0)\n",
    "        avg_I_tau = np.mean(all_I_tau, axis=0)\n",
    "        std_I_tau = np.std(all_I_tau, axis=0)\n",
    "\n",
    "        # Deterministic SIR\n",
    "        ax.plot(t, S_det, color='cornflowerblue', label=\"Susceptible (Deterministic)\", linestyle=\"--\")\n",
    "        ax.plot(t, I_det, color='purple', label=\"Infectious (Deterministic)\", linestyle=\"--\")\n",
    "\n",
    "        # Average Stochastic SIR using GA\n",
    "        ax.plot(t, avg_S_GA, color='green', label=\"Avg Susceptible (GA)\")\n",
    "        ax.fill_between(t, avg_S_GA - std_S_GA, avg_S_GA + std_S_GA, color='green', alpha=0.2)\n",
    "        ax.plot(t, avg_I_GA, color='red', label=\"Avg Infectious (GA)\")\n",
    "        ax.fill_between(t, avg_I_GA - std_I_GA, avg_I_GA + std_I_GA, color='red', alpha=0.2)\n",
    "\n",
    "        # Average Stochastic SIR using Tau-Leaping\n",
    "        ax.plot(t, avg_S_tau, color='darkcyan', label=\"Avg Susceptible (Tau-Leaping)\")\n",
    "        ax.fill_between(t, avg_S_tau - std_S_tau, avg_S_tau + std_S_tau, color='darkcyan', alpha=0.2)\n",
    "        ax.plot(t, avg_I_tau, color='orange', label=\"Avg Infectious (Tau-Leaping)\")\n",
    "        ax.fill_between(t, avg_I_tau - std_I_tau, avg_I_tau + std_I_tau, color='orange', alpha=0.2)\n",
    "\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.set_ylabel(\"Population\")\n",
    "        ax.set_title(f\"Comparison of Deterministic, GA, and Tau-Leaping ({num_runs} runs)\")\n",
    "        ax.legend(loc=\"center right\")\n",
    "        ax.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "S0_slider = widgets.IntSlider(value=90, min=0, max=1000, step=10, description='S0:')\n",
    "I0_slider = widgets.IntSlider(value=10, min=0, max=100, step=10, description='I0:')\n",
    "tau_slider = widgets.FloatSlider(value=0.1, min=0.0, max=1000.0, step=0.1, description='tau:')\n",
    "num_runs_slider = widgets.IntSlider(value=1, min=1, max=1000, description='Runs:')\n",
    "\n",
    "interactive_plot = widgets.interactive(update_plot, S0=S0_slider, I0=I0_slider, tau=tau_slider, num_runs=num_runs_slider)\n",
    "display(interactive_plot, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate Simulation Variability and Negative Co-variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GA_with_demography(S0, I0, R0, beta, gamma, Lambda, mu, max_time):\n",
    "    # Initial conditions\n",
    "    S, I, R = S0, I0, R0\n",
    "    t = 0\n",
    "    times = [t]\n",
    "    S_values = [S]\n",
    "    I_values = [I]\n",
    "    R_values = [R]\n",
    "\n",
    "    while t < max_time and I > 0:\n",
    "        N = S + I + R\n",
    "\n",
    "        # Calculate propensities\n",
    "        a1 = beta * S * I / N        # Transmission\n",
    "        a2 = gamma * I               # Recovery\n",
    "        a3 = Lambda                  # Birth\n",
    "        a4 = mu * S                  # Death of a susceptible\n",
    "        a5 = mu * I                  # Death of an infected\n",
    "        a6 = mu * R                  # Death of a recovered\n",
    "        \n",
    "        a0 = a1 + a2 + a3 + a4 + a5 + a6\n",
    "\n",
    "        # Time until next event\n",
    "        dt = -np.log(np.random.random()) / a0\n",
    "        t += dt\n",
    "\n",
    "        # Determine which event occurs\n",
    "        r = np.random.random() * a0\n",
    "        if r < a1:\n",
    "            # Transmission event\n",
    "            S -= 1\n",
    "            I += 1\n",
    "        elif r < a1 + a2:\n",
    "            # Recovery event\n",
    "            I -= 1\n",
    "            R += 1\n",
    "        elif r < a1 + a2 + a3:\n",
    "            # Birth event\n",
    "            S += 1\n",
    "        elif r < a1 + a2 + a3 + a4:\n",
    "            # Death of a susceptible\n",
    "            S -= 1\n",
    "        elif r < a1 + a2 + a3 + a4 + a5:\n",
    "            # Death of an infected\n",
    "            I -= 1\n",
    "        else:\n",
    "            # Death of a recovered\n",
    "            R -= 1\n",
    "\n",
    "        # Store results\n",
    "        times.append(t)\n",
    "        S_values.append(S)\n",
    "        I_values.append(I)\n",
    "        R_values.append(R)\n",
    "\n",
    "    return times, S_values, I_values, R_values\n",
    "\n",
    "# Parameters\n",
    "S0= 990\n",
    "I0= 10\n",
    "R0= 0\n",
    "Lambda = 0.05  # birth rate\n",
    "mu = 0.05  # death rate\n",
    "max_time = 70\n",
    "t = np.linspace(0, max_time, 1000)\n",
    "\n",
    "# Parameters\n",
    "beta_values = [0.8, 0.9, 0.99]\n",
    "gamma_values = [0.05, 0.1, 0.3]\n",
    "num_runs = 100\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for beta in beta_values:\n",
    "    for gamma in gamma_values:\n",
    "        all_S = []\n",
    "        all_I = []\n",
    "        end_times = []\n",
    "        for _ in range(num_runs):\n",
    "            times, S_values, I_values, _ = GA_with_demography(S0, I0, R0, beta, gamma, Lambda, mu, max_time)\n",
    "\n",
    "            S_interp = np.interp(t, times, S_values)\n",
    "            I_interp = np.interp(t, times, I_values)\n",
    "            \n",
    "            below_10_percent = np.where(I_interp <= 0.1 * I0)[0]\n",
    "            if below_10_percent.size > 0:\n",
    "                end_time = t[below_10_percent[0]]\n",
    "                end_times.append(end_time)\n",
    "\n",
    "            all_S.append(S_interp)\n",
    "            all_I.append(I_interp)\n",
    "\n",
    "        if not end_times:\n",
    "            continue\n",
    "\n",
    "        end_time=max(end_times)\n",
    "\n",
    "        # Covariance experiment\n",
    "        start_time = 0\n",
    "        start_index = np.where(t >= start_time)[0][0]\n",
    "        end_index = np.where(t <= end_time)[0][-1] + 1\n",
    "\n",
    "        # Compute mean and covariance\n",
    "        mean_S = np.mean(all_S, axis=0)\n",
    "        mean_I = np.mean(all_I, axis=0)\n",
    "        mean_S_mod = np.mean([s[start_index:end_index] for s in all_S], axis=0)\n",
    "        mean_I_mod = np.mean([i[start_index:end_index] for i in all_I], axis=0)\n",
    "        std_S = np.std(S_values, axis=0)\n",
    "        std_I = np.std(I_values, axis=0)\n",
    "        covariance_SI = np.cov(mean_S_mod, mean_I_mod)[0, 1]\n",
    "        corr_coefficient = covariance_SI / (std_S * std_I)\n",
    "\n",
    "        # Run deterministic model\n",
    "        solution = odeint(SIR_demography, [S0, I0, R0], t, args=(beta, gamma, Lambda, mu))\n",
    "        S_det, I_det, R_det = solution.T\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'beta': beta,\n",
    "            'gamma': gamma,\n",
    "            'mean_S': mean_S,\n",
    "            'mean_I': mean_I,\n",
    "            'covariance_SI': covariance_SI,\n",
    "            'corr_coefficient': corr_coefficient,\n",
    "            'S_det': S_det,\n",
    "            'I_det': I_det\n",
    "        })\n",
    "\n",
    "# Create a grid of subplots\n",
    "num_beta = len(beta_values)\n",
    "num_gamma = len(gamma_values)\n",
    "fig, axes = plt.subplots(num_beta, num_gamma, figsize=(15, 15))\n",
    "\n",
    "first_plot = True\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    ax = axes[i // num_gamma][i % num_gamma]\n",
    "    \n",
    "    ax.plot(t, res['mean_S'], label=\"Mean Susceptible (Stochastic)\" if first_plot else \"\", color=\"orange\")\n",
    "    ax.plot(t, res['mean_I'], label=\"Mean Infectious (Stochastic)\" if first_plot else \"\", color=\"red\")\n",
    "    ax.plot(t, res['S_det'], label=\"Susceptible (Deterministic)\" if first_plot else \"\", color=\"orange\", linestyle=\"--\")\n",
    "    ax.plot(t, res['I_det'], label=\"Infectious (Deterministic)\" if first_plot else \"\", color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    ax.set_title(f\"β={res['beta']}, γ={res['gamma']}\\nCorrelation coefficient (S,I)={res['corr_coefficient']:.2f}\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Population\")\n",
    "    ax.grid(True)\n",
    "    \n",
    "    \n",
    "    first_plot = False\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, wspace=0.3, hspace=0.5)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Resonance and Increased Transients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "S0= 990\n",
    "I0=10\n",
    "R0=0\n",
    "gamma = 0.1 \n",
    "Lambda = 5  # birth rate\n",
    "mu = 0.01  # death rate\n",
    "max_time = 200\n",
    "t = np.linspace(0, max_time, 1000)\n",
    "N_values = np.linspace(100, 5000, 25).astype(int)  \n",
    "R0_values = np.linspace(2.0, 10.0, 25)\n",
    "gamma = 0.1 \n",
    "max_time = 160\n",
    "t_common = np.linspace(0, max_time, 1000)\n",
    "num_runs = 100\n",
    "\n",
    "transients = []\n",
    "\n",
    "transient_S_matrix = np.zeros((len(N_values), len(R0_values)))\n",
    "transient_I_matrix = np.zeros((len(N_values), len(R0_values)))\n",
    "\n",
    "def measure_transient(stochastic, deterministic):\n",
    "    absolute_transient = np.max(np.abs(stochastic - deterministic))\n",
    "    return absolute_transient / np.max(deterministic)\n",
    "\n",
    "\n",
    "for i, N in enumerate(N_values):\n",
    "    for j, R0 in enumerate(R0_values):\n",
    "        beta = R0 * gamma\n",
    "        \n",
    "        I0 = 5\n",
    "        S0 = N - I0 - R0\n",
    "\n",
    "        S_accum = np.zeros_like(t_common)\n",
    "        I_accum = np.zeros_like(t_common)\n",
    "        \n",
    "        for _ in range(num_runs):\n",
    "            times, S_stoch, I_stoch, R_stoch = GA_with_demography(S0, I0, R0, beta, gamma, Lambda, mu, max_time)\n",
    "            \n",
    "            S_stoch_interp = np.interp(t_common, times, S_stoch)\n",
    "            I_stoch_interp = np.interp(t_common, times, I_stoch)\n",
    "            \n",
    "            S_accum += S_stoch_interp\n",
    "            I_accum += I_stoch_interp\n",
    "        \n",
    "        S_stoch_mean = S_accum / num_runs\n",
    "        I_stoch_mean = I_accum / num_runs\n",
    "        \n",
    "        solution = odeint(SIR_demography, [S0, I0, R0], t, args=(beta, gamma, Lambda, mu))\n",
    "        S_det, I_det, R_det = solution.T\n",
    "        \n",
    "        transient_S = measure_transient(S_stoch_mean, S_det)\n",
    "        transient_I = measure_transient(I_stoch_mean, I_det)\n",
    "        \n",
    "        transient_S_matrix[i, j] = transient_S\n",
    "        transient_I_matrix[i, j] = transient_I\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "c1 = ax[0].imshow(transient_S_matrix, cmap='viridis', aspect='auto', origin='lower',\n",
    "                  extent=[min(R0_values), max(R0_values), min(N_values), max(N_values)])\n",
    "fig.colorbar(c1, ax=ax[0])\n",
    "ax[0].set_title('Relative Transient for Susceptible')\n",
    "ax[0].set_xlabel('R0')\n",
    "ax[0].set_ylabel('N')\n",
    "\n",
    "c2 = ax[1].imshow(transient_I_matrix, cmap='viridis', aspect='auto', origin='lower',\n",
    "                  extent=[min(R0_values), max(R0_values), min(N_values), max(N_values)])\n",
    "fig.colorbar(c2, ax=ax[1])\n",
    "ax[1].set_title('Relative Transient for Infectious')\n",
    "ax[1].set_xlabel('R0')\n",
    "ax[1].set_ylabel('N')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_transient(stochastic, deterministic):\n",
    "    return np.max(np.abs(stochastic - deterministic))\n",
    "\n",
    "# Parameters\n",
    "S0 = 950\n",
    "I0 = 50\n",
    "R0 = 0\n",
    "beta = 0.3\n",
    "gamma = 0.1\n",
    "Lambda = 5  # birth rate\n",
    "mu = 0.01  # death rate\n",
    "max_time = 200\n",
    "t = np.linspace(0, max_time, 1000)\n",
    "\n",
    "# Main plotting function\n",
    "def plot_transient(N, beta, gamma, Lambda, mu):\n",
    "    # Adjust initial conditions based on N\n",
    "    I0 = 10\n",
    "    S0 = N - I0 - R0\n",
    "    \n",
    "    # Solve ODE for deterministic SIR\n",
    "    solution = odeint(SIR_demography, [S0, I0, R0], t, args=(beta, gamma, Lambda, mu))\n",
    "    S_det, I_det, R_det = solution.T\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(t, S_det, label=\"Susceptible (Deterministic)\", color=\"orange\", linestyle=\"--\")\n",
    "    plt.plot(t, I_det, label=\"Infectious (Deterministic)\", color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    # Run and plot multiple stochastic simulations\n",
    "    for _ in range(10):\n",
    "        times, S_stoch, I_stoch, R_stoch = GA_with_demography(S0, I0, R0, beta, gamma, Lambda, mu, max_time)\n",
    "        \n",
    "        # Interpolate stochastic results onto common time grid\n",
    "        S_stoch_interp = np.interp(t, times, S_stoch)\n",
    "        I_stoch_interp = np.interp(t, times, I_stoch)\n",
    "        \n",
    "        plt.plot(t, S_stoch_interp, color=\"orange\", alpha=0.2)\n",
    "        plt.plot(t, I_stoch_interp, color=\"red\", alpha=0.2)\n",
    "    \n",
    "    plt.title(f\"N={N:.0f}, β={beta:.2f}, γ={gamma:.2f}, λ={Lambda:.3f}, μ={mu:.3f}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Population\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Sliders for parameters\n",
    "N_slider = FloatSlider(value=1000, min=100, max=5000, step=100, description='N')\n",
    "beta_slider = FloatSlider(value=0.5, min=0.1, max=1, step=0.01, description='β')\n",
    "gamma_slider = FloatSlider(value=0.05, min=0.01, max=0.1, step=0.01, description='γ')\n",
    "Lambda_slider = FloatSlider(value=10, min=0.001, max=10, step=0.001, description='λ')\n",
    "mu_slider = FloatSlider(value=0.01, min=0.001, max=0.1, step=0.001, description='μ')\n",
    "\n",
    "# Display the interactive plot\n",
    "interact(plot_transient, N=N_slider, beta=beta_slider, gamma=gamma_slider, Lambda=Lambda_slider, mu=mu_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extinction events and Critical Community Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: it will take a while to run the code for this part of the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_values = np.concatenate([\n",
    "    np.arange(100, 1000, 100),      \n",
    "    np.arange(1000, 10000, 100), \n",
    "])\n",
    "\n",
    "R0 = 3 \n",
    "gamma = 0.1  \n",
    "beta = R0 * gamma \n",
    "num_runs = 100\n",
    "max_time = 500  \n",
    "\n",
    "results = []\n",
    "\n",
    "for N in N_values:\n",
    "    extinction_times = []\n",
    "    \n",
    "    for _ in range(num_runs):\n",
    "        times, _, I_values, _ = gillespie_algorithm(N-1, 1, 0, beta, gamma, max_time)\n",
    "        extinction_time = times[next((i for i, val in enumerate(I_values) if val == 0), len(times)-1)]\n",
    "        extinction_times.append(extinction_time)\n",
    "    \n",
    "    avg_extinction_time = np.mean(extinction_times)\n",
    "    \n",
    "    results.append({\n",
    "        'N': N,\n",
    "        'avg_extinction_time': avg_extinction_time\n",
    "    })\n",
    "\n",
    "times = [res['avg_extinction_time'] for res in results]\n",
    "\n",
    "def exp_decay(x, a, b, c):\n",
    "    return a * np.log(b * x) + c\n",
    "\n",
    "popt, pcov = curve_fit(exp_decay, N_values, times, p0=(1, 0.1, 1))\n",
    "a, b, c = popt\n",
    "\n",
    "\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "print(f\"a = {popt[0]:.5f} ± {perr[0]:.5f}\")\n",
    "print(f\"b = {popt[1]:.5f} ± {perr[1]:.5f}\")\n",
    "print(f\"c (convergence value) = {popt[2]:.5f} ± {perr[2]:.5f}\")\n",
    "\n",
    "\n",
    "# Plotting original data and the fit\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(N_values, times, '-o', color='darkcyan', label='Individual extinction time', markersize=6)\n",
    "plt.plot(N_values, exp_decay(N_values, *popt), 'darkorange', linestyle=\"--\", label='Extinction convergence curve')\n",
    "plt.xlabel(\"Population Size (N)\")\n",
    "plt.ylabel(\"Average Time to Extinction (Timesteps)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "R0_values = np.concatenate([\n",
    "    np.arange(0.1, 1, 0.1), \n",
    "    np.arange(1, 10, 0.5),  \n",
    "    np.arange(10, 51, 5)   \n",
    "])\n",
    "gamma = 0.1  \n",
    "N = 1000  \n",
    "num_runs = 100\n",
    "max_time = 500 \n",
    "\n",
    "results = []\n",
    "\n",
    "for R0 in R0_values:\n",
    "    beta = R0 * gamma  \n",
    "    extinction_times = []\n",
    "    \n",
    "    for _ in range(num_runs):\n",
    "        times, _, I_values, _ = gillespie_SIR(N-1, 1, 0, beta, gamma, max_time)\n",
    "        \n",
    "        extinction_time = times[next((i for i, val in enumerate(I_values) if val == 0), len(times)-1)]\n",
    "        extinction_times.append(extinction_time)\n",
    "    \n",
    "    avg_extinction_time = np.mean(extinction_times)\n",
    "    \n",
    "    results.append({\n",
    "        'R0': R0,\n",
    "        'avg_extinction_time': avg_extinction_time\n",
    "    })\n",
    "\n",
    "times = [res['avg_extinction_time'] for res in results]\n",
    "\n",
    "\n",
    "def exp_decay(x, a, b, c):\n",
    "    return a * np.exp(b * x) + c\n",
    "popt, pcov = curve_fit(exp_decay, R0_values, times, p0=(-1, -0.1, 1))\n",
    "a, b, c = popt\n",
    "\n",
    "perr = np.sqrt(np.diag(pcov))\n",
    "print(f\"a = {popt[0]:.5f} ± {perr[0]:.5f}\")\n",
    "print(f\"b = {popt[1]:.5f} ± {perr[1]:.5f}\")\n",
    "print(f\"c (convergence value) = {popt[2]:.5f} ± {perr[2]:.5f}\")\n",
    "\n",
    "\n",
    "# Plotting original data and the fit\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(R0_values, times, '-o', color='darkcyan', label='Individual extinction time', markersize=6)\n",
    "plt.plot(R0_values, exp_decay(R0_values, *popt), 'darkorange', linestyle=\"--\", label='Extinction convergence curve')\n",
    "plt.xlabel(r\"$R_0$\")\n",
    "plt.ylabel(\"Average Time to Extinction (Timesteps)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R0_values = np.concatenate([\n",
    "    np.arange(0.1, 1, 0.1),\n",
    "    np.arange(1, 10, 0.5)\n",
    "])\n",
    "N_values = [10, 50, 100, 500, 1000]\n",
    "gamma = 0.1  \n",
    "num_runs = 1000\n",
    "max_time = 500  \n",
    "\n",
    "results = np.zeros((len(N_values), len(R0_values)))\n",
    "\n",
    "for i, N in enumerate(N_values):\n",
    "    for j, R0 in enumerate(R0_values):\n",
    "        beta = R0 * gamma  \n",
    "        extinction_times = []\n",
    "        \n",
    "        for _ in range(num_runs):\n",
    "            times, _, I_values, _ = gillespie_SIR(N-1, 1, 0, beta, gamma, max_time)\n",
    "            extinction_time = times[next((i for i, val in enumerate(I_values) if val == 0), len(times)-1)]\n",
    "            extinction_times.append(extinction_time)\n",
    "        \n",
    "        # Calculate average time to extinction\n",
    "        avg_extinction_time = np.mean(extinction_times)\n",
    "        \n",
    "        results[i, j] = avg_extinction_time\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 7))\n",
    "c = plt.contourf(R0_values, N_values, results, cmap='viridis', levels=100)\n",
    "plt.colorbar(c, label=\"Average Time to Extinction (Timesteps)\")\n",
    "# plt.title(r\"Impact of $R_0$ and $N$ on Time to Extinction\")\n",
    "plt.xlabel(\"$R_0$\")\n",
    "plt.ylabel(\"Population Size (N)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
